{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed9187fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nCreated By  : Sayali Anil Alatkar \\nCreated Date: 06/01/2023 \\nversion ='1.1'\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3  \n",
    "# -*- coding: utf-8 -*- \n",
    "#----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "Created By  : Sayali Anil Alatkar \n",
    "Created Date: 06/01/2023 \n",
    "version ='1.1'\n",
    "\"\"\"\n",
    "# ---------------------------------------------------------------------------\n",
    "# Implementation for NestedGNN:Detecting Malicious Network Activity with Nested Graph Neural Networks \n",
    "# (doi: 10.1109/ICC45855.2022.9838698.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a6da75",
   "metadata": {},
   "source": [
    "Training GNN has the following steps:\n",
    "\n",
    "1. Creating graph batches with dataloaders\n",
    "2. Message passing to learn node embeddings with gcn/gat layers\n",
    "3. Readout to aggregate node embeddings\n",
    "4. Train classification loss on learned graph emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122f4d4",
   "metadata": {},
   "source": [
    "PsychAD contrasts: [link](https://docs.google.com/spreadsheets/d/1EAxMz9oSm4Ht-MFyo3dNo-FziTiqJvFgkQaDE1yxpyg/edit#gid=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2c54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7009afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from collections import OrderedDict, Counter\n",
    "os.environ['DGLBACKEND'] = 'pytorch'\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import dgl\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, average_precision_score\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from modified_gnnexplainer import NestedGNNExplainer\n",
    "from nested_gnn import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16fee4",
   "metadata": {},
   "source": [
    "##### Create dataloaders with batches (of 12 graphs) for batched training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3652803e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/dgl_graphs_cc_grn_filtered_train_(204_individuals).pkl', 'rb') as f:\n",
    "    train_patients = pickle.load(f)\n",
    "\n",
    "with open('./data/dgl_graphs_cc_grn_filtered_heldout_(204_individuals).pkl', 'rb') as f:\n",
    "    heldout_patients = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d913024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT TRAIN/TEST\n",
    "def generate_dataset(new_PsychAD2_GRN_Dataset,PsychAD2_5_CC_Dataset, patient_ids,\n",
    "                     train_labels,test_labels,train_patient_ids, test_patient_ids,\n",
    "                    num_cell_types = 12, OUTER_LAYER_BATCH = 10, INNER_LAYER_BATCH = 10*12):\n",
    "    \n",
    "    class GRN_train(DGLDataset):\n",
    "        def __init__(self):\n",
    "            super().__init__(name=\"GRN\")\n",
    "\n",
    "        def process(self):\n",
    "            self.graphs = train_grn_graphs\n",
    "            self.labels = train_grn_labels\n",
    "\n",
    "        def __getitem__(self, i):\n",
    "            return self.graphs[i], self.labels[i]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.graphs)\n",
    "    \n",
    "    class GRN_test(DGLDataset):\n",
    "        def __init__(self):\n",
    "            super().__init__(name=\"GRN\")\n",
    "\n",
    "        def process(self):\n",
    "            self.graphs = test_grn_graphs\n",
    "            self.labels = test_grn_labels\n",
    "\n",
    "\n",
    "        def __getitem__(self, i):\n",
    "            return self.graphs[i], self.labels[i]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.graphs)\n",
    "\n",
    "    class CC_train(DGLDataset):\n",
    "        def __init__(self):\n",
    "            super().__init__(name=\"CC\")\n",
    "\n",
    "        def process(self):\n",
    "            self.graphs = train_cc_graphs\n",
    "            self.labels = train_labels\n",
    "\n",
    "        def __getitem__(self, i):\n",
    "            return self.graphs[i], self.labels[i]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.graphs)\n",
    "\n",
    "    class CC_test(DGLDataset):\n",
    "        def __init__(self):\n",
    "            super().__init__(name=\"CC\")\n",
    "\n",
    "        def process(self):\n",
    "            self.graphs = test_cc_graphs\n",
    "            self.labels = test_labels\n",
    "\n",
    "\n",
    "        def __getitem__(self, i):\n",
    "            return self.graphs[i], self.labels[i]\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.graphs)\n",
    "\n",
    "    #train_patient_ids, test_patient_ids, train_labels, test_labels = train_test_split(patient_ids,labels, test_size=0.1, random_state=42, stratify=labels)\n",
    "\n",
    "    train_grn_labels = [val for val in train_labels for _ in range(12)]\n",
    "    test_grn_labels = [val for val in test_labels for _ in range(12)]\n",
    "\n",
    "    train_dataset_grn, test_dataset_grn={},{}\n",
    "    train_dataset_cc, test_dataset_cc={},{}\n",
    "\n",
    "    for pid in patient_ids:\n",
    "        if pid in train_patient_ids:\n",
    "            train_dataset_grn[pid] = new_PsychAD2_GRN_Dataset[pid]\n",
    "            train_dataset_cc[pid] = PsychAD2_5_CC_Dataset[pid]\n",
    "        else:\n",
    "            test_dataset_grn[pid] = new_PsychAD2_GRN_Dataset[pid]\n",
    "            test_dataset_cc[pid] = PsychAD2_5_CC_Dataset[pid]\n",
    "            \n",
    "     \n",
    "    train_grn_graphs = [v1 for k,v in train_dataset_grn.items() for k1,v1 in v.items()]\n",
    "    test_grn_graphs = [v1 for k,v in test_dataset_grn.items() for k1,v1 in v.items()]\n",
    "\n",
    "    train_cc_graphs = [v for k,v in train_dataset_cc.items() ]\n",
    "    test_cc_graphs = [v for k,v in test_dataset_cc.items()]\n",
    "\n",
    "    train_grn_obj = GRN_train()\n",
    "    test_grn_obj = GRN_test()\n",
    "\n",
    "    train_cc_obj = CC_train()\n",
    "    test_cc_obj = CC_test()\n",
    "    \n",
    "    # CREATE DATALOADERS\n",
    "    train_grn_dataloader = GraphDataLoader(train_grn_obj, batch_size=INNER_LAYER_BATCH, drop_last=False)\n",
    "    test_grn_dataloader = GraphDataLoader(test_grn_obj, batch_size=INNER_LAYER_BATCH, drop_last=False)\n",
    "\n",
    "    train_cc_dataloader = GraphDataLoader(train_cc_obj, batch_size=OUTER_LAYER_BATCH, drop_last=False)\n",
    "    test_cc_dataloader = GraphDataLoader(test_cc_obj, batch_size=OUTER_LAYER_BATCH, drop_last=False)\n",
    "\n",
    "    return train_grn_dataloader,test_grn_dataloader,train_cc_dataloader,test_cc_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3382ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_grn_obj,test_grn_obj,train_cc_obj,test_cc_obj = generate_dataset(new_PsychAD2_GRN_Dataset,PsychAD2_5_CC_Dataset,labels,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b47677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grn, train_cc, train_labels = train_patients[0], train_patients[1], train_patients[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b35a24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubID</th>\n",
       "      <th>label</th>\n",
       "      <th>label_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M10233</td>\n",
       "      <td>AD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M10282</td>\n",
       "      <td>AD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>M11371</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>M11588</td>\n",
       "      <td>AD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>M11589</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>M96977</td>\n",
       "      <td>AD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>M97728</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>M98107</td>\n",
       "      <td>AD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>M99645</td>\n",
       "      <td>AD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>M99877</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SubID    label  label_binary\n",
       "4     M10233       AD             1\n",
       "6     M10282       AD             1\n",
       "19    M11371  Control             0\n",
       "23    M11588       AD             1\n",
       "24    M11589  Control             0\n",
       "...      ...      ...           ...\n",
       "1002  M96977       AD             1\n",
       "1015  M97728  Control             0\n",
       "1020  M98107       AD             1\n",
       "1038  M99645       AD             1\n",
       "1039  M99877  Control             0\n",
       "\n",
       "[204 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[\"label_binary\"] = [1 if x==\"AD\" else 0 for x in train_labels[\"label\"].to_list()]\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d9e1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_ids = train_labels[\"SubID\"].to_list()\n",
    "labels = train_labels[\"label_binary\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08203f",
   "metadata": {},
   "source": [
    "##### Model for NestedGNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69ec9f",
   "metadata": {},
   "source": [
    "##### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eb8dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8805a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with given dimensions\n",
    "in_layer_dim=100\n",
    "out_layer_dim=4735\n",
    "\n",
    "h_dims = [256,128,2048,1024,512,256,128,64] # gnn layers = 2 inner + 4 outer\n",
    "output_dim = 2\n",
    "\n",
    "#model = NestedGNN(in_layer_dim, out_layer_dim, h_dims, output_dim)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001) \n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d480274",
   "metadata": {},
   "source": [
    "##### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f8fc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cell_types = 12\n",
    "OUTER_LAYER_BATCH = 10\n",
    "INNER_LAYER_BATCH = OUTER_LAYER_BATCH*num_cell_types\n",
    "epochs=50\n",
    "lr = 0.001\n",
    "gamma=0.9\n",
    "n_splits=5\n",
    "inner=\"GCN\" #/GAT\n",
    "outer=\"GCN\" #/GAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49026ee2",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31b69270",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch: 0\n",
      "Trainloss: 5993660351464.699\tTrain BACC: 0.54441\n",
      "Val Loss::2057930224435.2334\tVal BACC:0.5\n",
      "Epoch: 10\n",
      "Trainloss: 46708090916.06448\tTrain BACC: 0.48444\n",
      "Val Loss::129801877367.50142\tVal BACC:0.5\n",
      "Epoch: 20\n",
      "Trainloss: 0.05509\tTrain BACC: 0.5\n",
      "Val Loss::0.05731\tVal BACC:0.5\n",
      "Epoch: 30\n",
      "Trainloss: 0.04887\tTrain BACC: 0.57937\n",
      "Val Loss::0.05296\tVal BACC:0.5625\n",
      "Epoch: 40\n",
      "Trainloss: 0.04386\tTrain BACC: 0.68899\n",
      "Val Loss::0.05437\tVal BACC:0.5\n",
      "Epoch: 49\n",
      "Trainloss: 0.03869\tTrain BACC: 0.6965\n",
      "Val Loss::0.04899\tVal BACC:0.68182\n",
      "AUPRC on Validation set:0.81344\n",
      "\n",
      "Fold 2\n",
      "Epoch: 0\n",
      "Trainloss: 610689212453.105\tTrain BACC: 0.4721\n",
      "Val Loss::113913364480.06589\tVal BACC:0.5\n",
      "Epoch: 10\n",
      "Trainloss: 2233160783.70787\tTrain BACC: 0.49265\n",
      "Val Loss::0.07207\tVal BACC:0.5\n",
      "Epoch: 20\n",
      "Trainloss: 0.0439\tTrain BACC: 0.57871\n",
      "Val Loss::0.08372\tVal BACC:0.5\n",
      "Epoch: 30\n",
      "Trainloss: 65864325652.8621\tTrain BACC: 0.58569\n",
      "Val Loss::330115495.77125\tVal BACC:0.5\n",
      "Epoch: 40\n",
      "Trainloss: 13656936917.41693\tTrain BACC: 0.78196\n",
      "Val Loss::0.08931\tVal BACC:0.65385\n",
      "Epoch: 49\n",
      "Trainloss: 0.03163\tTrain BACC: 0.77281\n",
      "Val Loss::0.10654\tVal BACC:0.57692\n",
      "AUPRC on Validation set:0.59259\n",
      "\n",
      "Fold 3\n",
      "Epoch: 0\n",
      "Trainloss: 4326012392658.7217\tTrain BACC: 0.49593\n",
      "Val Loss::1395491512037.5518\tVal BACC:0.5\n",
      "Epoch: 10\n",
      "Trainloss: 4028133588.34172\tTrain BACC: 0.56059\n",
      "Val Loss::36252815783.75994\tVal BACC:0.5\n",
      "Epoch: 20\n",
      "Trainloss: 0.03765\tTrain BACC: 0.79355\n",
      "Val Loss::0.04227\tVal BACC:0.67917\n",
      "Epoch: 30\n",
      "Trainloss: 5484958731.97582\tTrain BACC: 0.79355\n",
      "Val Loss::2889985624.31154\tVal BACC:0.47917\n",
      "Epoch: 40\n",
      "Trainloss: 0.0086\tTrain BACC: 0.97482\n",
      "Val Loss::0.05458\tVal BACC:0.47917\n",
      "Epoch: 49\n",
      "Trainloss: 0.03944\tTrain BACC: 0.79247\n",
      "Val Loss::0.10516\tVal BACC:0.5\n",
      "AUPRC on Validation set:0.82759\n",
      "\n",
      "Fold 4\n",
      "Epoch: 0\n",
      "Trainloss: 1103760672602.2507\tTrain BACC: 0.4893\n",
      "Val Loss::183416950077.8217\tVal BACC:0.5\n",
      "Epoch: 10\n",
      "Trainloss: 2212066813.82928\tTrain BACC: 0.64366\n",
      "Val Loss::0.05253\tVal BACC:0.55797\n",
      "Epoch: 20\n",
      "Trainloss: 3287400335.14977\tTrain BACC: 0.82457\n",
      "Val Loss::2930821331.89653\tVal BACC:0.55797\n",
      "Epoch: 30\n",
      "Trainloss: 0.02653\tTrain BACC: 0.87504\n",
      "Val Loss::0.0541\tVal BACC:0.66667\n",
      "Epoch: 40\n",
      "Trainloss: 2321595868.31668\tTrain BACC: 0.84243\n",
      "Val Loss::1452630016.02487\tVal BACC:0.62319\n",
      "Epoch: 49\n",
      "Trainloss: 0.03637\tTrain BACC: 0.82693\n",
      "Val Loss::0.05073\tVal BACC:0.7029\n",
      "AUPRC on Validation set:0.86822\n",
      "\n",
      "Fold 5\n",
      "Epoch: 0\n",
      "Trainloss: 7014622579562.613\tTrain BACC: 0.47234\n",
      "Val Loss::0.11291\tVal BACC:0.5\n",
      "Epoch: 10\n",
      "Trainloss: 2708002271.82528\tTrain BACC: 0.5\n",
      "Val Loss::0.06399\tVal BACC:0.5\n",
      "Epoch: 20\n",
      "Trainloss: 58302786.49555\tTrain BACC: 0.57382\n",
      "Val Loss::0.06115\tVal BACC:0.5\n",
      "Epoch: 30\n",
      "Trainloss: 6566754341.42796\tTrain BACC: 0.61681\n",
      "Val Loss::7232192229.54344\tVal BACC:0.425\n",
      "Epoch: 40\n",
      "Trainloss: 1728276802.40936\tTrain BACC: 0.74093\n",
      "Val Loss::0.06329\tVal BACC:0.53056\n",
      "Epoch: 49\n",
      "Trainloss: 352354902.05528\tTrain BACC: 0.78365\n",
      "Val Loss::0.07643\tVal BACC:0.53056\n",
      "AUPRC on Validation set:0.703\n",
      "\n",
      "Fold 6\n",
      "Epoch: 0\n",
      "Trainloss: 11399560701082.049\tTrain BACC: 0.45801\n",
      "Val Loss::1890635463009.113\tVal BACC:0.5\n",
      "Epoch: 10\n",
      "Trainloss: 6104122003.10948\tTrain BACC: 0.49073\n",
      "Val Loss::6488091118.36222\tVal BACC:0.5\n",
      "Epoch: 20\n",
      "Trainloss: 4731412987.80523\tTrain BACC: 0.61294\n",
      "Val Loss::4078721942.07825\tVal BACC:0.5\n",
      "Epoch: 30\n",
      "Trainloss: 1580428588.96852\tTrain BACC: 0.73934\n",
      "Val Loss::1724393577.93694\tVal BACC:0.67\n",
      "Epoch: 40\n",
      "Trainloss: 650813278.53967\tTrain BACC: 0.85786\n",
      "Val Loss::2507494929.66425\tVal BACC:0.73\n",
      "Epoch: 49\n",
      "Trainloss: 14077831.46758\tTrain BACC: 0.89559\n",
      "Val Loss::150878190.35116\tVal BACC:0.73\n",
      "AUPRC on Validation set:0.92064\n",
      "\n",
      "Fold 7\n",
      "Epoch: 0\n",
      "Trainloss: 2175715759349.5435\tTrain BACC: 0.50855\n",
      "Val Loss::717708256644.45\tVal BACC:0.5\n",
      "Epoch: 10\n",
      "Trainloss: 13059902752.46626\tTrain BACC: 0.49231\n",
      "Val Loss::8497152000.03552\tVal BACC:0.5\n",
      "Epoch: 20\n",
      "Trainloss: 3796294885.67206\tTrain BACC: 0.51111\n",
      "Val Loss::2367883475.88111\tVal BACC:0.48052\n",
      "Epoch: 30\n",
      "Trainloss: 11351982.51801\tTrain BACC: 0.70256\n",
      "Val Loss::0.06243\tVal BACC:0.57143\n",
      "Epoch: 40\n",
      "Trainloss: 161518071.51402\tTrain BACC: 0.71368\n",
      "Val Loss::0.05996\tVal BACC:0.57143\n",
      "Epoch: 49\n",
      "Trainloss: 0.03183\tTrain BACC: 0.83248\n",
      "Val Loss::0.07712\tVal BACC:0.57143\n",
      "AUPRC on Validation set:0.78571\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=7,random_state=1, shuffle=True)\n",
    "\n",
    "patient_ids = np.array(patient_ids)\n",
    "labels = np.array(labels)\n",
    "\n",
    "models={}\n",
    "\n",
    "for i,kfsplit in enumerate(kf.split(patient_ids)):\n",
    "    print (f\"\\nFold {i+1}\")\n",
    "    \n",
    "    train_patient_ids, test_patient_ids = patient_ids[kfsplit[0]], patient_ids[kfsplit[1]]\n",
    "    train_labels, test_labels = labels[kfsplit[0]], labels[kfsplit[1]]\n",
    "        \n",
    "    train_grn_dataloader,test_grn_dataloader,train_cc_dataloader,test_cc_dataloader=generate_dataset(\n",
    "        train_grn, train_cc, patient_ids, train_labels, test_labels,\n",
    "        train_patient_ids, test_patient_ids, num_cell_types = num_cell_types, \n",
    "        OUTER_LAYER_BATCH = OUTER_LAYER_BATCH, INNER_LAYER_BATCH = INNER_LAYER_BATCH)\n",
    "    \n",
    "    model = NestedGNN(in_layer_dim, out_layer_dim, h_dims, output_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001) \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        num_correct = 0\n",
    "        num_tests = 0\n",
    "        total_loss = 0\n",
    "        total_examples = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        ep_loss=[]\n",
    "        for (batched_grn_graph, labels_grn), (batched_cc_graph, labels_cc) in \\\n",
    "            zip(train_grn_dataloader, train_cc_dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batched_grn_graph,batched_cc_graph, \n",
    "                         batched_grn_graph.ndata[\"x\"].float(), batched_cc_graph.ndata[\"x\"].float())\n",
    "\n",
    "            # TRY WEIGHTED LOSS FUNCTION:\n",
    "            #Weight = [0.1, 0.9]\n",
    "            #args.loss_fn = nn.CrossEntropyLoss(torch.tensor(weight).to(device).float())\n",
    "            \n",
    "            loss = F.cross_entropy(pred, torch.tensor(labels_cc, dtype=torch.long))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            num_correct += (pred.argmax(1) == labels_cc).sum().item()\n",
    "            num_tests += len(labels_cc)\n",
    "\n",
    "            total_loss+=loss.detach().numpy()\n",
    "            total_examples += batched_cc_graph.batch_size\n",
    "            ep_loss.append(total_loss/total_examples)\n",
    "\n",
    "            y_true += labels_cc\n",
    "            y_pred += pred.argmax(1)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if epoch%10 == 0 or epoch == epochs-1:\n",
    "            print (\"Epoch: {}\".format(epoch))\n",
    "            \n",
    "            train_loss = round(np.mean(ep_loss),5)\n",
    "            train_bacc = round(balanced_accuracy_score(y_true, y_pred),5)\n",
    "            print (f\"Trainloss: {train_loss}\\tTrain BACC: {train_bacc}\")\n",
    "            #print(\"Train accuracy (Unbalanced):\", num_correct / num_tests)\n",
    "            \n",
    "            model.eval()\n",
    "            num_correct = 0\n",
    "            num_tests = 0\n",
    "            total_loss = 0\n",
    "            total_examples = 0\n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            b_loss=[]\n",
    "            for (batched_grn_graph, labels_grn), (batched_cc_graph, labels_cc) in \\\n",
    "                zip(test_grn_dataloader, test_cc_dataloader):\n",
    "\n",
    "                pred = model(batched_grn_graph,batched_cc_graph, \n",
    "                             batched_grn_graph.ndata[\"x\"].float(), batched_cc_graph.ndata[\"x\"].float())\n",
    "\n",
    "                loss = F.cross_entropy(pred, torch.tensor(labels_cc, dtype=torch.long))\n",
    "                num_correct += (pred.argmax(1) == labels_cc).sum().item()\n",
    "                num_tests += len(labels_cc)\n",
    "                y_true += labels_cc\n",
    "                y_pred += pred.argmax(1)\n",
    "                total_loss+=loss.detach().numpy()\n",
    "                total_examples += batched_cc_graph.batch_size\n",
    "                b_loss.append(round(total_loss/total_examples,2))\n",
    "                #print (\"Batch Loss:{}\".format(round(total_loss/total_examples,2)))\n",
    "            val_loss = round(total_loss/total_examples,5)\n",
    "            val_bacc = round(balanced_accuracy_score(y_true, y_pred),5)\n",
    "            print(f\"Val Loss::{val_loss}\\tVal BACC:{val_bacc}\")\n",
    "            \n",
    "            if epoch == epochs-1:\n",
    "                auprc = round(average_precision_score(y_true, y_pred),5)\n",
    "                print (f\"AUPRC on Validation set:{auprc}\")\n",
    "                models[i+1] = {\"model\": model.state_dict(), \n",
    "                               \"Train BACC\": train_bacc, \"Train loss\": train_loss,\n",
    "                               \"Val BACC\": val_bacc, \"Val loss\": val_loss,\n",
    "                               \"Val AUPRC\":auprc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7846d31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79035"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_prc = 0\n",
    "for i in models:\n",
    "    avg_prc += models[i][\"Val AUPRC\"]\n",
    "avg_prc/len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81000e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.614924"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bacc = 0\n",
    "for i in models:\n",
    "    avg_bacc += models[i][\"Val BACC\"]\n",
    "avg_bacc/len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97897c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 0, 33)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "tn, fp, fn, tp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cb71f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4],\n",
       "       [ 0, 33]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95c608a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12775042"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "num_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "35937da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE MODEL DICTIONARIES\n",
    "model_file = \"models\"+\"_cv\"+str(n_splits)+\"_epochs\"+str(epochs)+\"_lr\"+str(lr)+\"_gamma\"+str(gamma)+\\\n",
    "            \"_outerbatch\"+str(OUTER_LAYER_BATCH)+\"_inner\"+inner+\"_outer\"+outer+\\\n",
    "            \"_numofcelltypes\"+str(num_cell_types)+\".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a0002ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models_cv5_epochs50_lr0.001_gamma0.9_outerbatch10_innerGCN_outerGCN_numofcelltypes12.pkl'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d0589ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER=\"./models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "39e4c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_FOLDER+model_file, 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "d90fd8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NestedGNN(\n",
       "  (conv1): GraphConv(in=100, out=256, normalization=both, activation=None)\n",
       "  (conv2): GraphConv(in=256, out=128, normalization=both, activation=None)\n",
       "  (conv3): GraphConv(in=4863, out=2048, normalization=both, activation=None)\n",
       "  (conv4): GraphConv(in=2048, out=1024, normalization=both, activation=None)\n",
       "  (conv5): GraphConv(in=1024, out=512, normalization=both, activation=None)\n",
       "  (conv6): GraphConv(in=512, out=256, normalization=both, activation=None)\n",
       "  (classify): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c534c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15a15e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
